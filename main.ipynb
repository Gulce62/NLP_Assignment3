{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import math\n",
    "import nltk\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import custom_lemmatizer\n",
    "from scipy.stats import binom"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\gulce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\gulce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gulce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\gulce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\gulce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('universal_tagset')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "with open('Fyodor Dostoyevski Processed.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Tokenize the text with the nltk library\n",
    "tokens = nltk.word_tokenize(text)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 1425758\n"
     ]
    }
   ],
   "source": [
    "print('Number of tokens:', len(tokens))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['part', 'i', 'chapter', 'i', 'on', 'an', 'exceptionally', 'hot', 'evening', 'early', 'in', 'july', 'a', 'young', 'man', 'came', 'out', 'of', 'the', 'garret', 'in', 'which', 'he', 'lodged', 'in', 's.', 'place', 'and', 'walked', 'slowly', ',', 'as', 'though', 'in', 'hesitation', ',', 'towards', 'k.', 'bridge', '.', 'he', 'had', 'successfully', 'avoided', 'meeting', 'his', 'landlady', 'on', 'the', 'staircase', '.', 'his', 'garret', 'was', 'under', 'the', 'roof', 'of', 'a', 'high', ',', 'five-storied', 'house', 'and', 'was', 'more', 'like', 'a', 'cupboard', 'than', 'a', 'room', '.', 'the', 'landlady', 'who', 'provided', 'him', 'with', 'garret', ',', 'dinners', ',', 'and', 'attendance', ',', 'lived', 'on', 'the', 'floor', 'below', ',', 'and', 'every', 'time', 'he', 'went', 'out', 'he', 'was']\n"
     ]
    }
   ],
   "source": [
    "print(tokens[:100])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Find POS (part-of-speech) tags of the tokens with the nltk library\n",
    "pos_tags = nltk.pos_tag(tokens, tagset='universal')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('part', 'NOUN'), ('i', 'VERB'), ('chapter', 'NOUN'), ('i', 'NOUN'), ('on', 'ADP'), ('an', 'DET'), ('exceptionally', 'ADV'), ('hot', 'ADJ'), ('evening', 'VERB'), ('early', 'ADJ'), ('in', 'ADP'), ('july', 'NOUN'), ('a', 'DET'), ('young', 'ADJ'), ('man', 'NOUN'), ('came', 'VERB'), ('out', 'ADP'), ('of', 'ADP'), ('the', 'DET'), ('garret', 'NOUN'), ('in', 'ADP'), ('which', 'DET'), ('he', 'PRON'), ('lodged', 'VERB'), ('in', 'ADP'), ('s.', 'ADJ'), ('place', 'NOUN'), ('and', 'CONJ'), ('walked', 'VERB'), ('slowly', 'ADV'), (',', '.'), ('as', 'ADP'), ('though', 'ADP'), ('in', 'ADP'), ('hesitation', 'NOUN'), (',', '.'), ('towards', 'NOUN'), ('k.', 'VERB'), ('bridge', 'NOUN'), ('.', '.'), ('he', 'PRON'), ('had', 'VERB'), ('successfully', 'ADV'), ('avoided', 'VERB'), ('meeting', 'VERB'), ('his', 'PRON'), ('landlady', 'NOUN'), ('on', 'ADP'), ('the', 'DET'), ('staircase', 'NOUN'), ('.', '.'), ('his', 'PRON'), ('garret', 'NOUN'), ('was', 'VERB'), ('under', 'ADP'), ('the', 'DET'), ('roof', 'NOUN'), ('of', 'ADP'), ('a', 'DET'), ('high', 'ADJ'), (',', '.'), ('five-storied', 'ADJ'), ('house', 'NOUN'), ('and', 'CONJ'), ('was', 'VERB'), ('more', 'ADV'), ('like', 'ADP'), ('a', 'DET'), ('cupboard', 'NOUN'), ('than', 'ADP'), ('a', 'DET'), ('room', 'NOUN'), ('.', '.'), ('the', 'DET'), ('landlady', 'NOUN'), ('who', 'PRON'), ('provided', 'VERB'), ('him', 'PRON'), ('with', 'ADP'), ('garret', 'NOUN'), (',', '.'), ('dinners', 'NOUN'), (',', '.'), ('and', 'CONJ'), ('attendance', 'NOUN'), (',', '.'), ('lived', 'VERB'), ('on', 'ADP'), ('the', 'DET'), ('floor', 'NOUN'), ('below', 'ADP'), (',', '.'), ('and', 'CONJ'), ('every', 'DET'), ('time', 'NOUN'), ('he', 'PRON'), ('went', 'VERB'), ('out', 'ADP'), ('he', 'PRON'), ('was', 'VERB')]\n"
     ]
    }
   ],
   "source": [
    "print(pos_tags[:100])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Lemmatize the tokens using the WordNetLemmatizer in nltk with custom_lemmatizer class\n",
    "cm = custom_lemmatizer.custom_lemmatizer()\n",
    "lemmatized_tokens = [cm.lemmatize(pt) for pt in pos_tags]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['part', 'i', 'chapter', 'i', 'on', 'an', 'exceptionally', 'hot', 'evening', 'early', 'in', 'july', 'a', 'young', 'man', 'came', 'out', 'of', 'the', 'garret', 'in', 'which', 'he', 'lodged', 'in', 's.', 'place', 'and', 'walked', 'slowly', ',', 'as', 'though', 'in', 'hesitation', ',', 'towards', 'k.', 'bridge', '.', 'he', 'had', 'successfully', 'avoided', 'meeting', 'his', 'landlady', 'on', 'the', 'staircase', '.', 'his', 'garret', 'was', 'under', 'the', 'roof', 'of', 'a', 'high', ',', 'five-storied', 'house', 'and', 'was', 'more', 'like', 'a', 'cupboard', 'than', 'a', 'room', '.', 'the', 'landlady', 'who', 'provided', 'him', 'with', 'garret', ',', 'dinner', ',', 'and', 'attendance', ',', 'lived', 'on', 'the', 'floor', 'below', ',', 'and', 'every', 'time', 'he', 'went', 'out', 'he', 'was']\n"
     ]
    }
   ],
   "source": [
    "print(lemmatized_tokens[:100])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def calculate_unigram_frequencies(tokens):\n",
    "    # Calculate the frequencies of all the unigrams\n",
    "    unigram_frequencies = {}\n",
    "    for t in tokens:\n",
    "        if t in unigram_frequencies:\n",
    "            unigram_frequencies[t] += 1\n",
    "        else:\n",
    "            unigram_frequencies[t] = 1\n",
    "    return unigram_frequencies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "unigram_frequencies = calculate_unigram_frequencies(lemmatized_tokens)\n",
    "that_count = unigram_frequencies['that']\n",
    "the_count = unigram_frequencies['the']\n",
    "abject_count = unigram_frequencies['abject']\n",
    "london_count = unigram_frequencies['london']\n",
    "dot_count = unigram_frequencies['.']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of word 'that': 19429\n",
      "Count of word 'the': 48392\n",
      "Count of word 'abject': 21\n",
      "Count of word 'london': 2\n",
      "Count of word '.': 51738\n"
     ]
    }
   ],
   "source": [
    "print(\"Count of word 'that':\", that_count)\n",
    "print(\"Count of word 'the':\", the_count)\n",
    "print(\"Count of word 'abject':\", abject_count)\n",
    "print(\"Count of word 'london':\", london_count)\n",
    "print(\"Count of word '.':\", dot_count)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Get the stopwords list from https://gist.github.com/sebleier/554280\n",
    "response = requests.get(\"https://gist.githubusercontent.com/sebleier/554280/raw/7e0e4a1ce04c2bb7bd41089c9821dbcf6d0c786c/NLTK's%2520list%2520of%2520english%2520stopwords\")\n",
    "stopwords_list = response.text.split('\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', '']\n"
     ]
    }
   ],
   "source": [
    "print(stopwords_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def calculate_bigram_frequencies(tokens, window_size):\n",
    "    # Create all bigrams according to the given window size\n",
    "    bigrams = []\n",
    "    for i in range(len(tokens)):\n",
    "        for j in range(1, window_size+1):\n",
    "            if i+j < len(tokens):\n",
    "                bigrams.append((tokens[i], tokens[i+j]))\n",
    "    # Calculate the frequencies of all the bigrams\n",
    "    bigram_frequencies = {}\n",
    "    for b in bigrams:\n",
    "        if b in bigram_frequencies:\n",
    "            bigram_frequencies[b] += 1\n",
    "        else:\n",
    "            bigram_frequencies[b] = 1\n",
    "    all_bigrams = []\n",
    "    for b, f in bigram_frequencies.items():\n",
    "        all_bigrams.append(b)\n",
    "    return all_bigrams, bigram_frequencies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def find_collocation_candidates(bigram_frequencies, pos_tags, min_freq):\n",
    "    # Find the collocation candidates according to the required conditions\n",
    "    collocation_candidates = []\n",
    "    for b, f in bigram_frequencies.items():\n",
    "        # Check whether the bigram occurs more than the desired minimum frequency and ignore if it is less\n",
    "        if f < min_freq:\n",
    "            continue\n",
    "        # Check whether the bigram contains punctuation marks and ignore if it contains\n",
    "        word1, word2 = b\n",
    "        if not (word1.isalpha() and word2.isalpha()):\n",
    "            continue\n",
    "        # Check whether the bigram contains stopwords and ignore if it contains\n",
    "        if word1 in stopwords_list or word2 in stopwords_list:\n",
    "            continue\n",
    "        # Check whether the bigram is ADJ-NOUN or NOUN-NOUN form and ignore if it is not\n",
    "        pos1 = [t for w, t in pos_tags if w == word1]\n",
    "        pos2 = [t for w, t in pos_tags if w == word2]\n",
    "        if not((\"ADJ\" in pos1 and \"NOUN\" in pos2) or (\"NOUN\" in pos1 and \"NOUN\" in pos2)):\n",
    "            continue\n",
    "        # Add the bigram to collocation candidates list if it satisfies all the conditions\n",
    "        collocation_candidates.append(b)\n",
    "    return collocation_candidates"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "unigram_frequencies = calculate_unigram_frequencies(lemmatized_tokens)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "all_bigrams_1, bigram_frequencies_1 = calculate_bigram_frequencies(lemmatized_tokens, 1)\n",
    "collocation_candidates_1 = find_collocation_candidates(bigram_frequencies_1, pos_tags, 10)\n",
    "N_1 = sum(bigram_frequencies_1.values())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of the bigram 'magnificent capital' with windows of size 1: 1\n"
     ]
    }
   ],
   "source": [
    "magnificent_capital_count = bigram_frequencies_1[('magnificent', 'capital')]\n",
    "print(\"Count of the bigram 'magnificent capital' with windows of size 1:\", magnificent_capital_count)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\n"
     ]
    }
   ],
   "source": [
    "if (\"mr.\", \"skimpole\") in collocation_candidates_1:\n",
    "    print(\"Yes\")\n",
    "else:\n",
    "    print(\"No\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "all_bigrams_3, bigram_frequencies_3 = calculate_bigram_frequencies(lemmatized_tokens, 3)\n",
    "collocation_candidates_3 = find_collocation_candidates(bigram_frequencies_3, pos_tags, 10)\n",
    "N_3 = sum(bigram_frequencies_3.values())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of the bigram 'bright fire' with windows of size 3: 1\n"
     ]
    }
   ],
   "source": [
    "bright_fire_count = bigram_frequencies_3[('bright', 'fire')]\n",
    "print(\"Count of the bigram 'bright fire' with windows of size 3:\", bright_fire_count)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\n"
     ]
    }
   ],
   "source": [
    "if (\"spontaneous\", \"combustion\") in collocation_candidates_3:\n",
    "    print(\"Yes\")\n",
    "else:\n",
    "    print(\"No\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def calculate_t_score(c_bigram, c_word1, c_word2, N):\n",
    "    real_mean = c_bigram / N # p (MLE)\n",
    "    expected_mean = (c_word1 / N) * (c_word2 / N) # H0\n",
    "    variance = real_mean # for small p\n",
    "    t_score = (real_mean - expected_mean) / math.sqrt(variance / N)\n",
    "    return t_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def calculate_chi_square(c_bigram, c_word1, c_word2, N):\n",
    "    O11 = c_bigram # C(w1w2)\n",
    "    O12 = c_word1 - O11 # C(~w1w2)\n",
    "    O21 = c_word2 - O11 # C(w1~w2)\n",
    "    O22 = N - (O11 + O12 + O21) # C(~w1~w2)\n",
    "    chi_square = (N * (O11 * O22 - O12 * O21) ** 2) / ((O11 + O12) * (O11 + O21) * (O12 + O22) * (O21 + O22))\n",
    "    return chi_square"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def calculate_likelihood_ratio(c_bigram, c_word1, c_word2, N):\n",
    "    p = c_word2 / N\n",
    "    p1 = c_bigram / c_word1\n",
    "    p2 = (c_word2 - c_bigram) / (N - c_word1)\n",
    "\n",
    "    # Calculate the hypothesis likelihoods\n",
    "    LH1 = binom.pmf(c_bigram, c_word1, p) * binom.pmf(c_word2 - c_bigram, N - c_word1, p)\n",
    "    LH2 = binom.pmf(c_bigram, c_word1, p1) * binom.pmf(c_word2 - c_bigram, N - c_word1, p2)\n",
    "\n",
    "    # Replace the zero with some very small ε>0 to avoid zero-division or log(0)\n",
    "    epsilon = np.finfo(float).eps\n",
    "    LH1 = max(LH1, epsilon)\n",
    "    LH2 = max(LH2, epsilon)\n",
    "\n",
    "    likelihood_ratio = -2 * math.log(LH1 / LH2)\n",
    "    return likelihood_ratio"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def calculate_scores(all_bigrams, bigram_frequencies, N):\n",
    "    scores = []\n",
    "    for bigram in all_bigrams:\n",
    "        c_bigram = bigram_frequencies[bigram]\n",
    "        c_word1 = sum([f for b, f in bigram_frequencies.items() if bigram[0] in b])//2\n",
    "        c_word2 = sum([f for b, f in bigram_frequencies.items() if bigram[1] in b])//2\n",
    "        t_score = calculate_t_score(c_bigram, c_word1, c_word2, N)\n",
    "        chi_square = calculate_chi_square(c_bigram, c_word1, c_word2, N)\n",
    "        likelihood_ratio = calculate_likelihood_ratio(c_bigram, c_word1, c_word2, N)\n",
    "        scores.append((bigram, t_score, chi_square, likelihood_ratio, c_bigram, c_word1, c_word2))\n",
    "    return scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "scores_1 = calculate_scores(collocation_candidates_1, bigram_frequencies_1, N_1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# Sort by t-score (1) or chi-square (2) or likelihood ratio (3)\n",
    "sorted_t_score_1 = sorted(scores_1, key=lambda x: x[1], reverse=True)\n",
    "sorted_chi_square_1 = sorted(scores_1, key=lambda x: x[2], reverse=True)\n",
    "sorted_likelihood_ratio_1 = sorted(scores_1, key=lambda x: x[3], reverse=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "data_t_score_1 = []\n",
    "for i, (bigram, t_score, chi_square, likelihood_ratio, c_bigram, c_word1, c_word2) in enumerate(sorted_t_score_1[:20]):\n",
    "    data_t_score_1.append({\n",
    "        \"Rank\": i+1,\n",
    "        \"Bigram\": f\"{bigram[0]} {bigram[1]}\",\n",
    "        \"t-score\": t_score,\n",
    "        \"chi-square\": chi_square,\n",
    "        \"likelihood-ratio\": likelihood_ratio,\n",
    "        \"c(w1w2)\": c_bigram,\n",
    "        \"c(w1)\": c_word1,\n",
    "        \"c(w2)\": c_word2\n",
    "    })\n",
    "\n",
    "data_chi_square_1 = []\n",
    "for i, (bigram, t_score, chi_square, likelihood_ratio, c_bigram, c_word1, c_word2) in enumerate(sorted_chi_square_1[:20]):\n",
    "    data_chi_square_1.append({\n",
    "        \"Rank\": i+1,\n",
    "        \"Bigram\": f\"{bigram[0]} {bigram[1]}\",\n",
    "        \"t-score\": t_score,\n",
    "        \"chi-square\": chi_square,\n",
    "        \"likelihood-ratio\": likelihood_ratio,\n",
    "        \"c(w1w2)\": c_bigram,\n",
    "        \"c(w1)\": c_word1,\n",
    "        \"c(w2)\": c_word2\n",
    "    })\n",
    "\n",
    "data_likelihood_ratio_1 = []\n",
    "for i, (bigram, t_score, chi_square, likelihood_ratio, c_bigram, c_word1, c_word2) in enumerate(sorted_likelihood_ratio_1[:20]):\n",
    "    data_likelihood_ratio_1.append({\n",
    "        \"Rank\": i+1,\n",
    "        \"Bigram\": f\"{bigram[0]} {bigram[1]}\",\n",
    "        \"t-score\": t_score,\n",
    "        \"chi-square\": chi_square,\n",
    "        \"likelihood-ratio\": likelihood_ratio,\n",
    "        \"c(w1w2)\": c_bigram,\n",
    "        \"c(w1)\": c_word1,\n",
    "        \"c(w2)\": c_word2\n",
    "    })"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "df_sorted_t_score_1 = pd.DataFrame(data_t_score_1)\n",
    "df_sorted_chi_square_1 = pd.DataFrame(data_chi_square_1)\n",
    "df_sorted_likelihood_ratio_1 = pd.DataFrame(data_likelihood_ratio_1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Rank                   Bigram   t-score  c(w1w2)  c(w1)  c(w2)\n",
      "0      1      stepan trofimovitch 22.619069      512    525    513\n",
      "1      2       pyotr stepanovitch 22.547831      509    834    509\n",
      "2      3         varvara petrovna 20.534433      422    474    507\n",
      "3      4        katerina ivanovna 20.239065      410    427    635\n",
      "4      5  nikolay vsyevolodovitch 17.657104      312    518    312\n",
      "5      6        fyodor pavlovitch 17.052922      291    306    461\n",
      "6      7                  old man 16.857563      289   1356   2546\n",
      "7      8      nastasia philipovna 15.583748      243    417    251\n",
      "8      9                young man 15.140569      232    776   2546\n",
      "9     10                old woman 14.353161      208   1356   1047\n",
      "10    11         yulia mihailovna 14.175298      201    215    202\n",
      "11    12         pyotr petrovitch 13.100114      172    834    331\n",
      "12    13    lizabetha prokofievna 13.074941      171    185    177\n",
      "13    14               great deal 12.790646      164   1202    237\n",
      "14    15      dmitri fyodorovitch 12.720228      162    427    327\n",
      "15    16       evgenie pavlovitch 12.563966      158    227    461\n",
      "16    17          thousand rouble 11.980513      144    614    543\n",
      "17    18                long time 11.793031      143   1074   2623\n",
      "18    19                  go away 11.511941      136   1858   1342\n",
      "19    20     mavriky nikolaevitch 11.487925      132    149    132\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.float_format', '{:.6f}'.format)\n",
    "print(df_sorted_t_score_1[['Rank', 'Bigram', 't-score', 'c(w1w2)', 'c(w1)', 'c(w2)']])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Rank                  Bigram  chi-square  c(w1w2)  c(w1)  c(w2)\n",
      "0      1     stepan trofimovitch  1387728.43      512    525    513\n",
      "1      2    ippolit kirillovitch  1359440.81       41     43     41\n",
      "2      3       lef nicolaievitch  1359440.81       41     43     41\n",
      "3      4       avdotya romanovna  1341882.35      112    119    112\n",
      "4      5        yulia mihailovna  1326304.32      201    215    202\n",
      "5      6         nikodim fomitch  1316081.54       24     24     26\n",
      "6      7   lizabetha prokofievna  1273169.85      171    185    177\n",
      "7      8    mavriky nikolaevitch  1263071.68      132    149    132\n",
      "8      9     trifon borissovitch  1235650.87       39     45     39\n",
      "9     10      rodion romanovitch  1205266.43       82     97     82\n",
      "10    11      mihail makarovitch  1197632.52       21     25     21\n",
      "11    12  gavrila ardalionovitch  1173526.56       58     61     67\n",
      "12    13        arina prohorovna  1120123.57       39     44     44\n",
      "13    14        varvara petrovna  1056418.47      422    474    507\n",
      "14    15     semyon yakovlevitch  1034362.57       37     51     37\n",
      "15    16          kuzma kuzmitch   983274.48       20     29     20\n",
      "16    17        daria alexeyevna   980371.30       19     21     25\n",
      "17    18          darya pavlovna   935804.97       49     62     59\n",
      "18    19       katerina ivanovna   883755.64      410    427    635\n",
      "19    20      pyotr stepanovitch   869957.83      509    834    509\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "print(df_sorted_chi_square_1[['Rank', 'Bigram', 'chi-square', 'c(w1w2)', 'c(w1)', 'c(w2)']])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Rank                 Bigram  likelihood-ratio  c(w1w2)  c(w1)  c(w2)\n",
      "0      1   ippolit kirillovitch         69.521040       41     43     41\n",
      "1      2      lef nicolaievitch         69.521040       41     43     41\n",
      "2      3        nikodim fomitch         69.473603       24     24     26\n",
      "3      4     mihail makarovitch         68.994638       21     25     21\n",
      "4      5    trifon borissovitch         68.572449       39     45     39\n",
      "5      6         kuzma kuzmitch         68.402672       20     29     20\n",
      "6      7      avdotya romanovna         68.340263      112    119    112\n",
      "7      8     semyon zaharovitch         68.147640       10     51     10\n",
      "8      9    semyon yakovlevitch         67.918141       37     51     37\n",
      "9     10  mavriky mavrikyevitch         67.912991       11    149     11\n",
      "10    11     rodion romanovitch         67.697947       82     97     82\n",
      "11    12                    o u         67.662663       14    225     14\n",
      "12    13               von sohn         67.592173       19     74     19\n",
      "13    14   mavriky nikolaevitch         67.527414      132    149    132\n",
      "14    15            de cominges         67.478888       17    243     17\n",
      "15    16           father iosif         67.313039       19   1139     19\n",
      "16    17     marya kondratyevna         67.217767       26    125     26\n",
      "17    18      dmitri prokofitch         67.162036       23    427     23\n",
      "18    19       sofya matveyevna         66.788045       51    135     51\n",
      "19    20       sofya semyonovna         66.729425       71    135     71\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.float_format', '{:.6f}'.format)\n",
    "print(df_sorted_likelihood_ratio_1[['Rank', 'Bigram', 'likelihood-ratio', 'c(w1w2)', 'c(w1)', 'c(w2)']])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "scores_3 = calculate_scores(collocation_candidates_3, bigram_frequencies_3, N_3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# Sort by t-score (1) or chi-square (2) or likelihood ratio (3)\n",
    "sorted_t_score_3 = sorted(scores_3, key=lambda x: x[1], reverse=True)\n",
    "sorted_chi_square_3 = sorted(scores_3, key=lambda x: x[2], reverse=True)\n",
    "sorted_likelihood_ratio_3 = sorted(scores_3, key=lambda x: x[3], reverse=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "data_t_score_3 = []\n",
    "for i, (bigram, t_score, chi_square, likelihood_ratio, c_bigram, c_word1, c_word2) in enumerate(sorted_t_score_3[:20]):\n",
    "    data_t_score_3.append({\n",
    "        \"Rank\": i+1,\n",
    "        \"Bigram\": f\"{bigram[0]} {bigram[1]}\",\n",
    "        \"t-score\": t_score,\n",
    "        \"chi-square\": chi_square,\n",
    "        \"likelihood-ratio\": likelihood_ratio,\n",
    "        \"c(w1w2)\": c_bigram,\n",
    "        \"c(w1)\": c_word1,\n",
    "        \"c(w2)\": c_word2\n",
    "    })\n",
    "\n",
    "data_chi_square_3 = []\n",
    "for i, (bigram, t_score, chi_square, likelihood_ratio, c_bigram, c_word1, c_word2) in enumerate(sorted_chi_square_3[:20]):\n",
    "    data_chi_square_3.append({\n",
    "        \"Rank\": i+1,\n",
    "        \"Bigram\": f\"{bigram[0]} {bigram[1]}\",\n",
    "        \"t-score\": t_score,\n",
    "        \"chi-square\": chi_square,\n",
    "        \"likelihood-ratio\": likelihood_ratio,\n",
    "        \"c(w1w2)\": c_bigram,\n",
    "        \"c(w1)\": c_word1,\n",
    "        \"c(w2)\": c_word2\n",
    "    })\n",
    "\n",
    "data_likelihood_ratio_3 = []\n",
    "for i, (bigram, t_score, chi_square, likelihood_ratio, c_bigram, c_word1, c_word2) in enumerate(sorted_likelihood_ratio_3[:20]):\n",
    "    data_likelihood_ratio_3.append({\n",
    "        \"Rank\": i+1,\n",
    "        \"Bigram\": f\"{bigram[0]} {bigram[1]}\",\n",
    "        \"t-score\": t_score,\n",
    "        \"chi-square\": chi_square,\n",
    "        \"likelihood-ratio\": likelihood_ratio,\n",
    "        \"c(w1w2)\": c_bigram,\n",
    "        \"c(w1)\": c_word1,\n",
    "        \"c(w2)\": c_word2\n",
    "    })"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "df_sorted_t_score_3 = pd.DataFrame(data_t_score_3)\n",
    "df_sorted_chi_square_3 = pd.DataFrame(data_chi_square_3)\n",
    "df_sorted_likelihood_ratio_3 = pd.DataFrame(data_likelihood_ratio_3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Rank                   Bigram   t-score  c(w1w2)  c(w1)  c(w2)\n",
      "0      1      stepan trofimovitch 22.602372      512   1575   1539\n",
      "1      2       pyotr stepanovitch 22.521479      509   2501   1526\n",
      "2      3         varvara petrovna 20.518057      422   1421   1520\n",
      "3      4        katerina ivanovna 20.220295      410   1281   1904\n",
      "4      5  nikolay vsyevolodovitch 17.644302      312   1553    935\n",
      "5      6        fyodor pavlovitch 17.041366      291    917   1381\n",
      "6      7                  old man 16.603300      290   4066   7633\n",
      "7      8      nastasia philipovna 15.574371      243   1249    752\n",
      "8      9                young man 15.025591      234   2327   7633\n",
      "9     10                old woman 14.459309      215   4066   3140\n",
      "10    11         yulia mihailovna 14.171001      201    645    606\n",
      "11    12                  o clock 13.221849      175    675    579\n",
      "12    13    lizabetha prokofievna 13.071447      171    554    530\n",
      "13    14         pyotr petrovitch 13.070649      172   2501    992\n",
      "14    15               great deal 12.798607      165   3603    711\n",
      "15    16      dmitri fyodorovitch 12.704857      162   1280    981\n",
      "16    17       evgenie pavlovitch 12.552339      158    680   1381\n",
      "17    18                    ha ha 12.521412      157    677    677\n",
      "18    19          thousand rouble 12.474037      157   1840   1629\n",
      "19    20           hundred rouble 12.329844      153   1282   1629\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.float_format', '{:.6f}'.format)\n",
    "print(df_sorted_t_score_3[['Rank', 'Bigram', 't-score', 'c(w1w2)', 'c(w1)', 'c(w2)']])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Rank                  Bigram  chi-square  c(w1w2)  c(w1)  c(w2)\n",
      "0      1     stepan trofimovitch   461893.16      512   1575   1539\n",
      "1      2    ippolit kirillovitch   453091.95       41    129    123\n",
      "2      3       lef nicolaievitch   453091.95       41    129    123\n",
      "3      4       avdotya romanovna   447144.47      112    357    336\n",
      "4      5        yulia mihailovna   441833.13      201    645    606\n",
      "5      6         nikodim fomitch   438661.54       24     72     78\n",
      "6      7   lizabetha prokofievna   425730.11      171    554    530\n",
      "7      8    mavriky nikolaevitch   420847.60      132    447    396\n",
      "8      9     trifon borissovitch   411831.33       39    135    117\n",
      "9     10      mihail makarovitch   411103.42       21     74     62\n",
      "10    11      rodion romanovitch   404676.92       82    290    245\n",
      "11    12  gavrila ardalionovitch   391097.91       58    183    201\n",
      "12    13        arina prohorovna   373322.26       39    132    132\n",
      "13    14        varvara petrovna   352056.50      422   1421   1520\n",
      "14    15     semyon yakovlevitch   344737.95       37    153    111\n",
      "15    16                 o clock   334914.48      175    675    579\n",
      "16    17          kuzma kuzmitch   327731.26       20     87     60\n",
      "17    18        daria alexeyevna   326764.87       19     63     75\n",
      "18    19                wisp tow   323415.10       14     54     48\n",
      "19    20          darya pavlovna   311869.44       49    186    177\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "print(df_sorted_chi_square_3[['Rank', 'Bigram', 'chi-square', 'c(w1w2)', 'c(w1)', 'c(w2)']])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Rank                 Bigram  likelihood-ratio  c(w1w2)  c(w1)  c(w2)\n",
      "0      1     semyon zaharovitch         63.155763       10    153     30\n",
      "1      2  mavriky mavrikyevitch         62.924804       11    447     33\n",
      "2      3                je suis         62.794400       10    138     39\n",
      "3      4           thou wouldst         62.682332       11    506     39\n",
      "4      5             dark brown         62.548382       10    623     45\n",
      "5      6               wisp tow         62.528363       14     54     48\n",
      "6      7                    o u         62.443396       14    675     42\n",
      "7      8             full speed         62.244908       14    906     48\n",
      "8      9             eye glowed         62.241415       10   3588     57\n",
      "9     10              eye shone         62.236514       11   3588     54\n",
      "10    11       thousand roubles         62.172252       11   1840     57\n",
      "11    12       literary matinée         62.063738       10    198     69\n",
      "12    13            de cominges         62.061037       17    724     51\n",
      "13    14           fit coughing         61.979217       10    603     72\n",
      "14    15         kuzma kuzmitch         61.975095       20     87     60\n",
      "15    16     mihail makarovitch         61.974348       21     74     62\n",
      "16    17         printing press         61.959683       10     36     96\n",
      "17    18             saith unto         61.919759       12     39     90\n",
      "18    19               von sohn         61.905781       19    222     57\n",
      "19    20         pan vrublevsky         61.852921       15     87     71\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.float_format', '{:.6f}'.format)\n",
    "print(df_sorted_likelihood_ratio_3[['Rank', 'Bigram', 'likelihood-ratio', 'c(w1w2)', 'c(w1)', 'c(w2)']])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "scores_head_clerk = calculate_scores([('head', 'clerk')], bigram_frequencies_1, N_1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "df_scores_head_clerk = pd.DataFrame(scores_head_clerk, columns=[\"Bigram\", \"t-score\", \"chi-square\", \"likelihood-ratio\", \"c(w1w2)\", \"c(w1)\", \"c(w2)\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Bigram  t-score  chi-square  likelihood-ratio  c(w1w2)  c(w1)  c(w2)\n",
      "0  (head, clerk) 4.674126 6294.816683         60.603199       22    801    136\n"
     ]
    }
   ],
   "source": [
    "print(df_scores_head_clerk)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "scores_great_man = calculate_scores([('great', 'man')], bigram_frequencies_1, N_1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "df_scores_great_man = pd.DataFrame(scores_great_man, columns=[\"Bigram\", \"t-score\", \"chi-square\", \"likelihood-ratio\", \"c(w1w2)\", \"c(w1)\", \"c(w2)\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Bigram  t-score  chi-square  likelihood-ratio  c(w1w2)  c(w1)  c(w2)\n",
      "0  (great, man) 3.736722  117.402985         45.158766       18   1202   2546\n"
     ]
    }
   ],
   "source": [
    "print(df_scores_great_man)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
